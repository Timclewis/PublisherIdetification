{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707bab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.5.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random as r\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imghdr\n",
    "import os\n",
    "import datetime\n",
    "import PIL\n",
    "import io\n",
    "\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.applications import ResNet50V2, Xception, EfficientNetB3, EfficientNetB4, EfficientNetB5\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from collections import Counter\n",
    "from PIL import ImageFile, Image, ImageOps\n",
    "from sklearn.metrics import confusion_matrix\n",
    "  \n",
    "print(f'Tensorflow version {tf.version.VERSION}')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282d503",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1f337173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH_TRAIN = 'C:/Users/crims/Tensorflow/PublisherIdetification/realpublishers/training/'\n",
    "PATH_TEST = 'C:/Users/crims/Tensorflow/PublisherIdetification/realpublishers/testing/'\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, val_split, height, width, batch_size, steps):\n",
    "        self.val_split = val_split\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = steps\n",
    "        \n",
    "    def args(self):\n",
    "        return (self.width, self.height)\n",
    "    \n",
    "    def train_generator(self):    \n",
    "        train_generator = ImageDataGenerator(rescale=1./255, validation_split=self.val_split)\n",
    "        print('Training folder:')\n",
    "        self.train_data = train_generator.flow_from_directory(PATH_TRAIN, target_size=(self.width, self.height),\n",
    "                                                     class_mode = 'categorical', batch_size=self.batch_size, \n",
    "                                                     subset = 'training')\n",
    "        print('Validation folder:')\n",
    "        self.valid_data = train_generator.flow_from_directory(PATH_TRAIN, target_size=(self.width, self.height),\n",
    "                                                     class_mode = 'categorical', batch_size=self.batch_size, \n",
    "                                                     subset = 'validation')\n",
    "        print()\n",
    "\n",
    "    def test_generator(self):\n",
    "        test_generator = ImageDataGenerator(rescale=1./255)\n",
    "        print('Test folder:')\n",
    "        self.test_data = test_generator.flow_from_directory(PATH_TEST, target_size=(self.width, self.height), \n",
    "                                                   class_mode=None, batch_size=1, shuffle=False)\n",
    "        print()\n",
    "        \n",
    "    def generator_info(self):\n",
    "        self.class_num = self.train_data.num_classes\n",
    "        self.class_counter = list(Counter(self.train_data.classes).values())\n",
    "        self.class_names = list(self.train_data.class_indices)\n",
    "        self.labels = self.train_data.labels\n",
    "        print(f'Class name and # {dict(zip(self.class_names, self.class_counter))}')\n",
    "        print(f'Num files trained {self.batch_size * self.steps} and validated {(self.batch_size * self.steps * self.val_split):.0f} per epoch')\n",
    "        print(f'Images resized to {self.height}x{self.width} trained avg {(self.train_data.n  // (self.batch_size * self.steps)):.1f} epochs' )\n",
    "        print()\n",
    "        \n",
    "    def clean_data(self):\n",
    "        filenames = self.train_data.filenames\n",
    "        n = 0\n",
    "        while n < self.train_data.n:\n",
    "            path = f'{PATH_TRAIN}{filenames[n]}'\n",
    "            image = cv2.imread(path)\n",
    "            img_type = imghdr.what(path)\n",
    "            if img_type != \"jpeg\":\n",
    "                print(f'Removing image from {path}')\n",
    "                os.remove(path)\n",
    "                n += 1\n",
    "            else:\n",
    "                n += 1\n",
    "        print('All done!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4cb31d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training folder:\n",
      "Found 9809 images belonging to 4 classes.\n",
      "Validation folder:\n",
      "Found 3269 images belonging to 4 classes.\n",
      "\n",
      "Class name and # {'IEEE': 144, 'Macmillan': 2586, 'Springer Nature': 5768, 'Wolters Kluwer Health': 1311}\n",
      "Num files trained 3200 and validated 800 per epoch\n",
      "Images resized to 225x150 trained avg 3.0 epochs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Arguments: val_split, height, width, batch_size, steps\n",
    "dat1 = DataGenerator(0.25, 225, 150, 32, 100)\n",
    "dat1.train_generator()\n",
    "dat1.generator_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251049c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "81fff37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(DataGenerator):\n",
    "    def __init__(self, network, pooling, optimizer, learn_rate, epochs):\n",
    "        super(Model, self).__init__(*args)\n",
    "        self.network = network\n",
    "        self.lr = learn_rate\n",
    "        self.opt = optimizer\n",
    "        self.pool = pooling\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def compile_model(self):\n",
    "        base = self.network(include_top=False, weights='imagenet', \n",
    "                     input_shape=(self.width, self.height, 3), pooling=self.pool)\n",
    "        opt = self.opt(learning_rate=self.lr)\n",
    "        \n",
    "        x = base.output\n",
    "        x = layers.Dense(self.class_num, activation='softmax')(x)\n",
    "        self.model = tf.keras.Model(base.input, x)\n",
    "        self.model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer=opt)    \n",
    "              \n",
    "    def run_model(self, summary, save): \n",
    "        self.current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "        self.log_dir = f'{self.network.__name__}{self.pool}_{self.opt.__name__}lr{self.lr}_E{self.epochs}B{dat1.batch_size}-{current_time}'\n",
    "        tensorflow_callback = k.callbacks.TensorBoard(log_dir = f'tensorboard_logs/{self.log_dir}',\n",
    "                                                      histogram_freq=1, write_graph=True, write_images=True)\n",
    "        \n",
    "        history = self.model.fit(self.train_data, validation_data=self.valid_data, \n",
    "                            callbacks=[tensorflow_callback], epochs=self.epochs, \n",
    "                            steps_per_epoch=self.steps , validation_steps=(DataGenerator.steps * DataGenerator.val_split), \n",
    "                            batch_size=self.batch_size, verbose =1)\n",
    "        if summary == True:\n",
    "            self.model.summary()\n",
    "        if save == True:\n",
    "            self.model.save(f'{NETWORK}_publisherid - {current_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f75d1ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'width' and 'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-3ef01ff262e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# If the position of objects is important Avg pool if not Max Pooling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Arguments: network, pooling, optimizer, learn_rate, epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmod1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEfficientNetB4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#xception ~ 5e-4, efficient ~ 9e-5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmod1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Arguments: Summary, save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'width' and 'height'"
     ]
    }
   ],
   "source": [
    "# If the position of objects is important Avg pool if not Max Pooling \n",
    "# Arguments: network, pooling, optimizer, learn_rate, epochs\n",
    "mod1 = Model(EfficientNetB4, 'max', Adam, 8e-5, 30) #xception ~ 5e-4, efficient ~ 9e-5\n",
    "mod1.compile_model()\n",
    "# Arguments: Summary, save model\n",
    "#mod1.run_model(False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cae38",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe36c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensorboard:\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "        self.data = []\n",
    "        self.pubs = []\n",
    "        self.publisher_names = list(dat1.train_data.class_indices.keys())[0:dat1.class_num]\n",
    "        self.pubs = r.sample(range(0,dat1.class_counter[0]-1), samples) \n",
    "        self.pubs.extend(r.sample(range(dat1.class_counter[0],dat1.class_counter[1]+dat1.class_counter[0]-1), samples))\n",
    "        self.pubs.extend(r.sample(range(dat1.class_counter[0]+dat1.class_counter[1],dat1.class_counter[0]+dat1.class_counter[1]+dat1.class_counter[2]-1), samples))\n",
    "        self.pubs.extend(r.sample(range(dat1.class_counter[0]+dat1.class_counter[1]+dat1.class_counter[2],dat1.class_counter[0]+dat1.class_counter[1]+dat1.class_counter[2]+dat1.class_counter[3]-1), samples))\n",
    "        \n",
    "        for i in pubs:\n",
    "            img = load_img(dat1.train_data.filepaths[i])\n",
    "            img = img.resize((150,225)) # width x height\n",
    "            img_arr = np.asarray(img)\n",
    "            self.data.append(img_arr)\n",
    "            \n",
    "    # Code adapted from Tensorboard tutorial\n",
    "    def plot_to_image(figure):\n",
    "      # Save the plot to a PNG in memory.\n",
    "      buf = io.BytesIO()\n",
    "      plt.savefig(buf, format='png')\n",
    "      plt.close(figure)\n",
    "      buf.seek(0)\n",
    "      # Convert PNG buffer to TF image\n",
    "      image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "      # Add the batch dimension\n",
    "      image = tf.expand_dims(image, 0)\n",
    "      return image\n",
    "\n",
    "    def log_images(self):\n",
    "        logdir = f'tensorboard_logs/{mod1.log_dir}/image'\n",
    "        file_writer = tf.summary.create_file_writer(logdir)\n",
    "        # Data should be in (BATCH_SIZE, H, W, C) \n",
    "        assert np.size(np.shape(self.data)) == 4\n",
    "      # Create a figure to contain the plot.\n",
    "        figure = plt.figure(figsize=(10,10))\n",
    "        num_images = np.shape(data)[0]\n",
    "        size = int(np.ceil(np.sqrt(num_images)))\n",
    "\n",
    "        for i in range(len(pubs)):\n",
    "            # Start next subplot.\n",
    "            plt.subplot(size, size, i + 1, title=class_names[labels[pubs[i]]])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            #plt.imshow(data[i], cmap=plt.cm.binary)\n",
    "        return figure\n",
    "\n",
    "        with file_writer.as_default():        \n",
    "                tf.summary.image(f'{len(pubs)} examples of training data', self.plot_to_image(figure), max_outputs=len(pubs), step=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47517bc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BuildModel' object has no attribute 'log_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-8591abbfd9df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mten1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorboard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mten1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-75-9a3b9b836f1f>\u001b[0m in \u001b[0;36mlog_images\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlog_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mlogdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'tensorboard_logs/{mod1.log_dir}/image'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mfile_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# Data should be in (BATCH_SIZE, H, W, C)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BuildModel' object has no attribute 'log_dir'"
     ]
    }
   ],
   "source": [
    "ten1 = Tensorboard(3)\n",
    "ten1.log_images()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e90a6",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca5394",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def randimg_predict(self):\n",
    "        n = r.randint(0, dat1.valid_data.n)\n",
    "        filenames = dat1.valid_data.filenames\n",
    "        path = f'{PATH_TRAIN}{filenames[n]}'\n",
    "        pic = mpimg.imread(path)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(pic)\n",
    "        plt.show()\n",
    "\n",
    "        img = tf.keras.preprocessing.image.load_img(path, target_size=(dat1.width, dat1.height))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        img_processed = tf.keras.applications.xception.preprocess_input(img_batch)\n",
    "\n",
    "        prediction = mod1.model(img_processed, training=False)\n",
    "        Top_index = np.argsort(np.max(prediction, axis=0))[-1]\n",
    "        Second_index = np.argsort(np.max(prediction, axis=0))[-2]\n",
    "\n",
    "        sort = np.sort(max(prediction))\n",
    "        print(f'1st predict {dat1.class_names[Top_index]} with conf {round(sort[len(sort) - 1]*100)}%')\n",
    "        print(f'2nd predict {dat1.class_names[Second_index]} with conf {round(sort[len(sort) - 2] * 100)}%')           \n",
    "        print(f'Answer is {filenames[n][:]}')\n",
    "        \n",
    "    def batch_predict(self, steps):\n",
    "        self.steps = steps\n",
    "        mod1.model.evaluate(dat1.valid_data, batch_size=dat1.batch_size, steps=self.steps, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a305e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1 = Predictor()\n",
    "predict1.randimg_predict()\n",
    "predict1.batch_predict(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa32bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
