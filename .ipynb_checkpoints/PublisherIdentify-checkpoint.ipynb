{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "707bab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.5.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random as r\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imghdr\n",
    "import os\n",
    "import datetime\n",
    "import PIL\n",
    "import io\n",
    "import sklearn\n",
    "import itertools\n",
    "import csv\n",
    "\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.applications import ResNet50V2, Xception, EfficientNetB3, EfficientNetB4, EfficientNetB5\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from collections import Counter\n",
    "from PIL import ImageFile, Image, ImageOps\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "print(f'Tensorflow version {tf.version.VERSION}')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282d503",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "1f337173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH_TRAIN = 'C:/Users/crims/Tensorflow/PublisherIdetification/realpublishers/training/'\n",
    "PATH_TEST = 'C:/Users/crims/Tensorflow/PublisherIdetification/realpublishers/testing/'\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, val_split, height, width, batch_size, steps):\n",
    "        self.val_split = val_split\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = steps\n",
    "        \n",
    "    def train_generator(self):    \n",
    "        train_generator = ImageDataGenerator(rescale=1./255, validation_split=self.val_split)\n",
    "        print('Training folder:')\n",
    "        self.train_data = train_generator.flow_from_directory(PATH_TRAIN, target_size=(self.height, self.width),\n",
    "                                                     class_mode = 'categorical', batch_size=self.batch_size, \n",
    "                                                     subset = 'training')\n",
    "        print('Validation folder:')\n",
    "        self.valid_data = train_generator.flow_from_directory(PATH_TRAIN, target_size=(self.height, self.width),\n",
    "                                                     class_mode = 'categorical', batch_size=self.batch_size, \n",
    "                                                     subset = 'validation')\n",
    "\n",
    "    def test_generator(self):\n",
    "        test_generator = ImageDataGenerator(rescale=1./255)\n",
    "        print('Test folder:')\n",
    "        self.test_data = test_generator.flow_from_directory(PATH_TEST, target_size=(self.width, self.height), \n",
    "                                                   class_mode=None, batch_size=1, shuffle=False)\n",
    "        print()\n",
    "        \n",
    "    def generator_info(self):\n",
    "        # Print info about the generated data\n",
    "        self.class_num = self.train_data.num_classes\n",
    "        self.class_counter = list(Counter(self.train_data.classes).values())\n",
    "        self.class_counter_valid = list(Counter(self.valid_data.classes).values())\n",
    "        self.class_names = list(self.train_data.class_indices)\n",
    "        self.labels = self.train_data.labels\n",
    "        print(f'Train data class name and num {dict(zip(self.class_names, self.class_counter))}')\n",
    "        print(f'Valid data class name and num {dict(zip(self.class_names, self.class_counter_valid))}')\n",
    "        print(f'Num files trained {self.batch_size * self.steps} and validated {(self.batch_size * self.steps * self.val_split):.0f} per epoch')\n",
    "        print(f'Images resized to {self.height}x{self.width} trained avg {(self.train_data.n  // (self.batch_size * self.steps)):.1f} epochs' )\n",
    "        print()\n",
    "        \n",
    "    def clean_data(self):\n",
    "        # Remove nontype files from data folder (run once EVER for data)\n",
    "        filenames = self.test_data.filenames\n",
    "        n = 0\n",
    "        while n < self.test_data.n:\n",
    "            path = f'{PATH_TRAIN}{filenames[n]}'\n",
    "            image = cv2.imread(path)\n",
    "            img_type = imghdr.what(path)\n",
    "            if img_type != \"jpeg\":\n",
    "                print(f'Removing image from {path}')\n",
    "                os.remove(path)\n",
    "                n += 1\n",
    "            else:\n",
    "                n += 1\n",
    "        print('All done!') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8d1d8",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a103b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensorboard:\n",
    "    #Code from Tensorflow tutorial Tensorboard\n",
    "    @staticmethod\n",
    "    def plot_to_image(figure):\n",
    "      # Save the plot to a PNG in memory.\n",
    "      buf = io.BytesIO()\n",
    "      plt.savefig(buf, format='png')\n",
    "      plt.close(figure)\n",
    "      buf.seek(0)\n",
    "      # Convert PNG buffer to TF image\n",
    "      image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "      # Add the batch dimension\n",
    "      image = tf.expand_dims(image, 0)\n",
    "      return image\n",
    "    \n",
    "    @staticmethod           \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        figure = plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens, vmin=0, vmax=1)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_img(img_path):\n",
    "        #img = Image.open(StringIO(img_path))\n",
    "        img = tf.io.read_file(img_path)\n",
    "        # convert the compressed string to a 3D uint8 tensor\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        # resize the image to the desired size for your model\n",
    "        img = tf.image.resize(img, (200, 300))\n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_sprite(data):\n",
    "    # For B&W or greyscale images\n",
    "        if len(data.shape) == 3:\n",
    "            data = np.tile(data[..., np.newaxis], (1, 1, 1, 3))\n",
    "\n",
    "        n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "        padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0), (0, 0))\n",
    "        data = np.pad(data, padding, mode=\"constant\", constant_values=0)\n",
    "\n",
    "        # Tile images into sprite\n",
    "        data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3, 4))\n",
    "        # print(data.shape) => (n, image_height, n, image_width, 3)\n",
    "\n",
    "        data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "        # print(data.shape) => (n * image_height, n * image_width, 3)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251049c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "81fff37a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BuildModel(DataGenerator):\n",
    "    def __init__(self, data_generator, network, pooling, optimizer, learn_rate, epochs, samples):\n",
    "        self.width = data_generator.width\n",
    "        self.height = data_generator.height\n",
    "        self.class_num = data_generator.class_num\n",
    "        self.class_names = data_generator.class_names\n",
    "        self.steps = data_generator.steps\n",
    "        self.val_steps = data_generator.steps *  data_generator.val_split\n",
    "        self.batch_size = data_generator.batch_size\n",
    "        self.train_data = data_generator.train_data\n",
    "        self.valid_data = data_generator.valid_data\n",
    "        self.test_data = data_generator.test_data\n",
    "        \n",
    "        self.network = network\n",
    "        self.lr = learn_rate\n",
    "        self.opt = optimizer\n",
    "        self.pool = pooling\n",
    "        self.epochs = epochs\n",
    "        self.samples = samples\n",
    "        self.publisher_names = list(self.train_data.class_indices.keys())[0:self.class_num]\n",
    "        \n",
    "        # Create labels list\n",
    "        self.test_num = self.test_data.n / self.class_num\n",
    "        self.test_labels = np.repeat(list(range(0,(self.class_num))), self.test_num)\n",
    "        \n",
    "    def compile_model(self):\n",
    "        base = self.network(include_top=False, weights='imagenet', \n",
    "                     input_shape=(self.width, self.height, 3), pooling=self.pool)\n",
    "        opt = self.opt(learning_rate=self.lr)  \n",
    "        x = base.output\n",
    "        #x = layers.Dense(512, activation= 'relu')(x)\n",
    "        x = layers.Dense(self.class_num, activation='softmax')(x)\n",
    "        self.model = tf.keras.Model(base.input, x)\n",
    "        self.model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer=opt)\n",
    "        \n",
    "        self.embeddings = tf.keras.Model(inputs=self.model.inputs, \n",
    "                                         outputs=self.model.layers[-2].output)\n",
    "    \n",
    "    def run_model(self, summary, proj, save): \n",
    "        if summary == True:\n",
    "            self.model.summary()\n",
    "            \n",
    "        self.current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "        self.log_dir = f'{self.network.__name__}{self.pool}_{self.opt.__name__}lr{self.lr}_E{self.epochs}B{self.batch_size}-{self.current_time}'\n",
    "        \n",
    "        cm_callback = k.callbacks.LambdaCallback(on_epoch_end= self.log_confusion_matrix)\n",
    "        image_callback = k.callbacks.LambdaCallback(on_epoch_end= self.log_images)\n",
    "        scalar_callback = k.callbacks.TensorBoard(log_dir = f'tensorboard_logs/{self.log_dir}',\n",
    "                                                      update_freq=100, histogram_freq=1, profile_batch=(90,100),\n",
    "                                                      write_graph=True, write_images=True)\n",
    "        \n",
    "        self.file_writer_cm = tf.summary.create_file_writer(f'tensorboard_logs/{self.log_dir}/cm')\n",
    "        self.file_writer_image = tf.summary.create_file_writer(f'tensorboard_logs/{self.log_dir}/image')\n",
    "\n",
    "        self.model.fit(self.train_data, validation_data= self.valid_data, \n",
    "                       callbacks=[scalar_callback, cm_callback, image_callback], epochs=self.epochs, \n",
    "                       steps_per_epoch=self.steps , validation_steps=self.val_steps, \n",
    "                       batch_size=self.batch_size, verbose=1)\n",
    "        \n",
    "        if proj == True:\n",
    "                #Make directory\n",
    "                log_dir = f'tensorboard_logs/projector'\n",
    "                if not os.path.exists(log_dir):\n",
    "                    os.makedirs(log_dir)\n",
    "                \n",
    "                # Generate embeddings\n",
    "                images_pil = []\n",
    "                images_embeddings = []\n",
    "                labels = []\n",
    "                for x in range(500):\n",
    "                    img_path = self.test_data.filepaths[x]\n",
    "                    img_tf = Tensorboard.get_img(img_path)\n",
    "                    \n",
    "                    # Save both tf image for prediction and PIL image for sprite\n",
    "                    img_pil = np.array(Image.open(img_path).resize((70, 100)))\n",
    "                    img_embedding = self.embeddings(tf.expand_dims(img_tf, axis=0))\n",
    "                    images_embeddings.append(np.array(img_embedding[0]))\n",
    "                    images_pil.append(img_pil)\n",
    "                    # Assuming your output data is directly the label\n",
    "                    label = img_path[77:] \n",
    "                    labels.append(label)\n",
    "                    \n",
    "                    with open(f'{log_dir}/embeddings/metadata.tsv', 'w') as file: \n",
    "                         for label in labels:\n",
    "                            file.write(f'{label}\\n')\n",
    "                    \n",
    "                with open(f'{log_dir}/embeddings/feature_vecs.tsv', 'w') as fw:\n",
    "                    csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "                    csv_writer.writerows(images_embeddings)\n",
    "                      \n",
    "                one_square_size = int(np.ceil(np.sqrt(len(images_embeddings))))\n",
    "                master_width = 70 * one_square_size\n",
    "                master_height = 100 * one_square_size\n",
    "                spriteimage = Image.new(\n",
    "                            mode='RGBA',\n",
    "                            size=(master_width, master_height),\n",
    "                            color=(0,0,0,0))\n",
    "                      \n",
    "                for count, image in enumerate(images_pil):\n",
    "                    div, mod = divmod(count, one_square_size)\n",
    "                    h_loc = 100 * div\n",
    "                    w_loc = 70 * mod\n",
    "                    image = Image.fromarray(image)\n",
    "                    spriteimage.paste(image, (w_loc, h_loc, w_loc+70, h_loc+100))\n",
    "                \n",
    "                #spriteimage.convert('RGB').save(f'{log_dir}/sprite.png', transparency=0)\n",
    "                spriteimage.save(f'{log_dir}/embeddings/sprite.png')\n",
    "                \n",
    "        if save == True:\n",
    "            self.model.save(f'{self.network.__name__}_publisherid - {self.current_time}')\n",
    "            \n",
    "    def log_confusion_matrix(self, epoch, logs):  \n",
    "        # Use the model to predict the values from the test_images.\n",
    "        test_pred_raw = self.model.predict(self.test_data)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix using sklearn.metrics\n",
    "        cm = sklearn.metrics.confusion_matrix(self.test_labels, test_pred)\n",
    "        figure = Tensorboard.plot_confusion_matrix(cm, class_names=self.class_names)\n",
    "        cm_image = Tensorboard.plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with self.file_writer_cm.as_default():\n",
    "            tf.summary.image(f'{self.network.__name__}-{self.current_time}', cm_image, step=epoch)\n",
    "            \n",
    "    def log_images(self, epoch, logs):\n",
    "        # Create pubs list\n",
    "        self.pubs = list(r.sample(range(0,49), self.samples)) \n",
    "        self.pubs.extend(r.sample(range(50, 99), self.samples))\n",
    "        self.pubs.extend(r.sample(range(100, 149), self.samples))\n",
    "        self.pubs.extend(r.sample(range(150, 199), self.samples))\n",
    "        # Create image paths from test_data\n",
    "        self.data = []\n",
    "        for i in self.pubs:\n",
    "            img = load_img(self.test_data.filepaths[i])\n",
    "            img = img.resize((self.width, self.height)) # width x height\n",
    "            img_arr = np.asarray(img)\n",
    "            self.data.append(img_arr)\n",
    "            \n",
    "        # Data should be in (BATCH_SIZE, H, W, C) \n",
    "        assert np.size(np.shape(self.data)) == 4\n",
    "        # Create a figure to contain the plot.\n",
    "        figure = plt.figure(figsize=(10,10))\n",
    "        num_images = np.shape(self.data)[0]\n",
    "        size = int(np.ceil(np.sqrt(num_images)))\n",
    "\n",
    "        for i in range(len(self.pubs)):\n",
    "            # Start next subplot.\n",
    "            plt.subplot(size, size, i + 1, title=self.class_names[self.test_labels[self.pubs[i]]])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(self.data[i], cmap=plt.cm.binary)\n",
    "\n",
    "        with self.file_writer_image.as_default():        \n",
    "                tf.summary.image(f'{self.network.__name__}-{self.current_time}', \n",
    "                                 Tensorboard.plot_to_image(figure), max_outputs=len(self.pubs), step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "e91e6d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training folder:\n",
      "Found 8310 images belonging to 4 classes.\n",
      "Validation folder:\n",
      "Found 2076 images belonging to 4 classes.\n",
      "Test folder:\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Train data class name and num {'IEEE': 949, 'Macmillan': 2862, 'Springer Nature': 3261, 'Wolters Kluwer Health': 1238}\n",
      "Valid data class name and num {'IEEE': 237, 'Macmillan': 715, 'Springer Nature': 815, 'Wolters Kluwer Health': 309}\n",
      "Num files trained 160 and validated 32 per epoch\n",
      "Images resized to 300x200 trained avg 51.0 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crims\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 8s 454ms/step - loss: 0.9077 - acc: 0.6313 - val_loss: 0.9705 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "#Args: valid split, width, height, batch_size, steps\n",
    "# batch_size = 32 for Xception and 12 for efficientB5, 16 for B4, 24 for B3\n",
    "dat1 = DataGenerator(0.20, 300, 200, 16, 10)\n",
    "dat1.train_generator()\n",
    "dat1.test_generator()\n",
    "dat1.generator_info()\n",
    "\n",
    "# If the position of objects is important Avg pool if not Max Pooling \n",
    "# Arguments: network, pooling, optimizer, learn_rate, epochs, samples\n",
    "mod1 = BuildModel(dat1, Xception, 'avg', Adam, 5e-4, 1, 4) #xception ~ 5e-4, efficient ~ 9e-5\n",
    "mod1.compile_model()\n",
    "mod1.run_model(False, True, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e90a6",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca5394",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Predictor(BuildModel):\n",
    "    def __init__(self, build_model):\n",
    "        self.test_data = build_model.test_data\n",
    "        self.valid_data = build_model.valid_data\n",
    "        self.test_labels = build_model.test_labels\n",
    "        self.width = build_model.width\n",
    "        self.height = build_model.height\n",
    "        self.model = build_model.model\n",
    "        self.class_names = build_model.class_names\n",
    "        self.batch_size = build_model.batch_size\n",
    "             \n",
    "    def img_predict(self):\n",
    "        n = r.randint(0, self.test_data.n)\n",
    "        filenames = self.valid_data.filenames\n",
    "        path = f'{PATH_TRAIN}{filenames[n]}'\n",
    "        pic = mpimg.imread(path)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(pic)\n",
    "        plt.show()\n",
    "\n",
    "        img = tf.keras.preprocessing.image.load_img(path, target_size=(self.width, self.height))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        img_processed = tf.keras.applications.xception.preprocess_input(img_batch)\n",
    "\n",
    "        prediction = self.model(img_processed, training=False)\n",
    "        Top_index = np.argsort(np.max(prediction, axis=0))[-1]\n",
    "        Second_index = np.argsort(np.max(prediction, axis=0))[-2]\n",
    "\n",
    "        sort = np.sort(max(prediction))\n",
    "        print(f'1st predict {self.class_names[Top_index]} with conf {round(sort[len(sort) - 1]*100)}%')\n",
    "        print(f'2nd predict {self.class_names[Second_index]} with conf {round(sort[len(sort) - 2] * 100)}%')           \n",
    "        print(f'Answer is {filenames[n][:]}')\n",
    "        \n",
    "    def batch_evaluate(self, num_batches):\n",
    "        self.steps = num_batches\n",
    "        self.model.evaluate(self.valid_data, batch_size=self.batch_size, steps=self.steps)\n",
    "        \n",
    "    def batch_predict(self, num_predicts):\n",
    "        i = num_predicts\n",
    "        test_pred_raw = self.model.predict(self.test_data)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "        test_labels = self.test_labels\n",
    "        acc = sum(1 for x,y in zip(test_pred[0:i], test_labels[0:i]) if x == y) / len(test_labels[0:i])\n",
    "        print(f'Accuracy of predictions is {acc*100}%')        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a305e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = Predictor(mod1)\n",
    "pred1.img_predict()\n",
    "pred1.batch_predict(100)\n",
    "pred1.batch_evaluate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43961d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
