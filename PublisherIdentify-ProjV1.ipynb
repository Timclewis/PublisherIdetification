{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "707bab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.5.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random as r\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imghdr\n",
    "import os\n",
    "import datetime\n",
    "import PIL\n",
    "import io\n",
    "import sklearn\n",
    "import itertools\n",
    "import shutil\n",
    "\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "from tensorflow.keras.applications import ResNet50V2, Xception, EfficientNetB3, EfficientNetB4, EfficientNetB5\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from collections import Counter\n",
    "from PIL import ImageFile, Image, ImageOps\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorboard.plugins import projector\n",
    "import tensorflow_datasets\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "print(f'Tensorflow version {tf.version.VERSION}')\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282d503",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f337173",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH_TRAIN = 'C:/Users/crims/Tensorflow/PublisherIdetification/realpublishers/training/'\n",
    "PATH_TEST = 'C:/Users/crims/Tensorflow/PublisherIdetification/realpublishers/testing/'\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, val_split, width, height, batch_size, steps):\n",
    "        self.val_split = val_split\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = steps\n",
    "        \n",
    "    def train_generator(self):    \n",
    "        train_generator = ImageDataGenerator(rescale=1./255, validation_split=self.val_split)\n",
    "        print('Training folder:')\n",
    "        self.train_data = train_generator.flow_from_directory(PATH_TRAIN, target_size=(self.width, self.height),\n",
    "                                                     class_mode = 'categorical', batch_size=self.batch_size, \n",
    "                                                     subset = 'training')\n",
    "        print('Validation folder:')\n",
    "        self.valid_data = train_generator.flow_from_directory(PATH_TRAIN, target_size=(self.width, self.height),\n",
    "                                                     class_mode = 'categorical', batch_size=self.batch_size, \n",
    "                                                     subset = 'validation')\n",
    "        print()\n",
    "\n",
    "    def test_generator(self):\n",
    "        test_generator = ImageDataGenerator(rescale=1./255)\n",
    "        print('Test folder:')\n",
    "        self.test_data = test_generator.flow_from_directory(PATH_TEST, target_size=(self.width, self.height), \n",
    "                                                   class_mode=None, batch_size=1, shuffle=False)\n",
    "        print()\n",
    "        \n",
    "    def generator_info(self):\n",
    "        # Print info about the generated data\n",
    "        self.class_num = self.train_data.num_classes\n",
    "        self.class_counter = list(Counter(self.train_data.classes).values())\n",
    "        self.class_counter_valid = list(Counter(self.valid_data.classes).values())\n",
    "        self.class_names = list(self.train_data.class_indices)\n",
    "        self.labels = self.train_data.labels\n",
    "        print(f'Train data class name and num {dict(zip(self.class_names, self.class_counter))}')\n",
    "        print(f'Valid data class name and num {dict(zip(self.class_names, self.class_counter_valid))}')\n",
    "        print(f'Num files trained {self.batch_size * self.steps} and validated {(self.batch_size * self.steps * self.val_split):.0f} per epoch')\n",
    "        print(f'Images resized to {self.height}x{self.width} trained avg {(self.train_data.n  // (self.batch_size * self.steps)):.1f} epochs' )\n",
    "        print()\n",
    "        \n",
    "    def clean_data(self):\n",
    "        # Remove nontype files from data folder (run once EVER for data)\n",
    "        filenames = self.train_data.filenames\n",
    "        n = 0\n",
    "        while n < self.train_data.n:\n",
    "            path = f'{PATH_TRAIN}{filenames[n]}'\n",
    "            image = cv2.imread(path)\n",
    "            img_type = imghdr.what(path)\n",
    "            if img_type != \"jpeg\":\n",
    "                print(f'Removing image from {path}')\n",
    "                os.remove(path)\n",
    "                n += 1\n",
    "            else:\n",
    "                n += 1\n",
    "        print('All done!') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8d1d8",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a103b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensorboard:\n",
    "    #Code from Tensorflow tutorial Tensorboard\n",
    "    @staticmethod\n",
    "    def plot_to_image(figure):\n",
    "      # Save the plot to a PNG in memory.\n",
    "      buf = io.BytesIO()\n",
    "      plt.savefig(buf, format='png')\n",
    "      plt.close(figure)\n",
    "      buf.seek(0)\n",
    "      # Convert PNG buffer to TF image\n",
    "      image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "      # Add the batch dimension\n",
    "      image = tf.expand_dims(image, 0)\n",
    "      return image\n",
    "    \n",
    "    @staticmethod           \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        # Normalize the confusion matrix.\n",
    "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        figure = plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens, vmin=0, vmax=1)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    # Code from https://gist.github.com/AndrewBMartin/ab06f4708124ccb4cacc4b158c3cef12\n",
    "    @staticmethod           \n",
    "    def create_sprite(data):\n",
    "        # For B&W or greyscale images\n",
    "        if len(data.shape) == 3:\n",
    "            data = np.tile(data[..., np.newaxis], (1, 1, 1, 3))\n",
    "\n",
    "        n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "        padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0), (0, 0))\n",
    "        data = np.pad(data, padding, mode=\"constant\", constant_values=0)\n",
    "\n",
    "        # Tile images into sprite\n",
    "        data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3, 4))\n",
    "        # print(data.shape) => (n, image_height, n, image_width, 3)\n",
    "\n",
    "        data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "        # print(data.shape) => (n * image_height, n * image_width, 3)\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_to_projector(x, feature_vector, y, class_names, \n",
    "                          log_dir=\"tensorboard_logs/projector\", meta_file=\"metadata.tsv\",):\n",
    "            \n",
    "        assert x.ndim == 4  # (BATCH, H, W, C)\n",
    "        if os.path.isdir(log_dir):\n",
    "            shutil.rmtree(log_dir)\n",
    "\n",
    "        # Create a new clean fresh folder :)\n",
    "        os.mkdir(log_dir)\n",
    "        SPRITES_FILE = os.path.join(log_dir, \"sprites.png\")\n",
    "        sprite = Tensorboard.create_sprite(x)\n",
    "        cv2.imwrite(SPRITES_FILE, sprite)\n",
    "\n",
    "        # Generate label names\n",
    "        labels = [class_names[list(y[i]).index(1)] for i in range(int(y.shape[0]))]\n",
    "\n",
    "        with open(os.path.join(log_dir, meta_file), \"w\") as f:\n",
    "            for label in labels:\n",
    "                f.write(\"{}\\n\".format(label))\n",
    "\n",
    "        if feature_vector.ndim != 2:\n",
    "            print(\n",
    "                \"NOTE: Feature vector is not of form (BATCH, FEATURES)\"\n",
    "                \" reshaping to try and get it to this form!\"\n",
    "            )\n",
    "            feature_vector = tf.reshape(feature_vector, [feature_vector.shape[0], -1])\n",
    "\n",
    "            feature_vector = tf.Variable(feature_vector)\n",
    "            checkpoint = tf.train.Checkpoint(embedding=feature_vector)\n",
    "            checkpoint.save(os.path.join(log_dir, \"embeddings.ckpt\"))\n",
    "\n",
    "            # Set up config\n",
    "            config = projector.ProjectorConfig()\n",
    "            embedding = config.embeddings.add()\n",
    "            embedding.tensor_name = \"embedding_file\"\n",
    "            embedding.metadata_path = meta_file\n",
    "            embedding.sprite.image_path = \"sprites.png\"\n",
    "            embedding.sprite.single_image_dim.extend((x.shape[1], x.shape[2]))\n",
    "            projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251049c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81fff37a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BuildModel(DataGenerator):\n",
    "    def __init__(self, data_generator, network, pooling, optimizer, learn_rate, epochs, samples):\n",
    "        self.width = data_generator.width\n",
    "        self.height = data_generator.height\n",
    "        self.class_num = data_generator.class_num\n",
    "        self.class_names = data_generator.class_names\n",
    "        self.steps = data_generator.steps\n",
    "        self.val_steps = data_generator.steps *  data_generator.val_split\n",
    "        self.batch_size = data_generator.batch_size\n",
    "        self.train_data = data_generator.train_data\n",
    "        self.valid_data = data_generator.valid_data\n",
    "        self.test_data = data_generator.test_data\n",
    "        \n",
    "        self.network = network\n",
    "        self.lr = learn_rate\n",
    "        self.opt = optimizer\n",
    "        self.pool = pooling\n",
    "        self.epochs = epochs\n",
    "        self.samples = samples\n",
    "        self.publisher_names = list(self.train_data.class_indices.keys())[0:self.class_num]\n",
    "        \n",
    "        # Create labels list\n",
    "        self.test_num = self.test_data.n / self.class_num\n",
    "        self.test_labels = np.repeat(list(range(0,(self.class_num))), self.test_num)\n",
    "        \n",
    "    def compile_model(self):\n",
    "        base = self.network(include_top=False, weights='imagenet', \n",
    "                     input_shape=(self.width, self.height, 3), pooling=self.pool)\n",
    "        opt = self.opt(learning_rate=self.lr)  \n",
    "        x = base.output\n",
    "        #x = layers.Dense(512, activation= 'relu')(x)\n",
    "        x = layers.Dense(self.class_num, activation='softmax')(x)\n",
    "        self.model = tf.keras.Model(base.input, x)\n",
    "        self.model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer=opt)\n",
    "    \n",
    "    def run_model(self, summary, proj, save): \n",
    "        if summary == True:\n",
    "            self.model.summary()\n",
    "            \n",
    "        self.current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "        self.log_dir = f'{self.network.__name__}{self.pool}_{self.opt.__name__}lr{self.lr}_E{self.epochs}B{self.batch_size}-{self.current_time}'\n",
    "        \n",
    "        cm_callback = k.callbacks.LambdaCallback(on_epoch_end= self.log_confusion_matrix)\n",
    "        image_callback = k.callbacks.LambdaCallback(on_epoch_end= self.log_images)\n",
    "        scalar_callback = k.callbacks.TensorBoard(log_dir = f'tensorboard_logs/{self.log_dir}',\n",
    "                                                      update_freq=100, histogram_freq=1, profile_batch=(40,50),\n",
    "                                                      write_graph=True, write_images=True)\n",
    "        \n",
    "        self.file_writer_cm = tf.summary.create_file_writer(f'tensorboard_logs/{self.log_dir}/cm')\n",
    "        self.file_writer_image = tf.summary.create_file_writer(f'tensorboard_logs/{self.log_dir}/image')\n",
    "\n",
    "        self.model.fit(self.train_data, validation_data= self.valid_data, \n",
    "                       callbacks=[scalar_callback, cm_callback, image_callback], epochs=self.epochs, \n",
    "                       steps_per_epoch=self.steps , validation_steps=self.val_steps, \n",
    "                       batch_size=self.batch_size, verbose=1)\n",
    "        \n",
    "        if proj == True:\n",
    "            LOG_DIR = 'tensorboard_logs/projector/test'\n",
    "            src = 'metadata.tsv'\n",
    "            dst = os.path.join(log_dir, 'metadata.tsv')\n",
    "            copyfile(src,dst)\n",
    "            \n",
    "            feature_vectors = np.lad\n",
    "            \n",
    "        if save == True:\n",
    "            self.model.save(f'{self.network.__name__}_publisherid - {self.current_time}')\n",
    "            \n",
    "    def log_confusion_matrix(self, epoch, logs):  \n",
    "        # Use the model to predict the values from the test_images.\n",
    "        test_pred_raw = self.model.predict(self.test_data)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix using sklearn.metrics\n",
    "        cm = sklearn.metrics.confusion_matrix(self.test_labels, test_pred)\n",
    "        figure = Tensorboard.plot_confusion_matrix(cm, class_names=self.class_names)\n",
    "        cm_image = Tensorboard.plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with self.file_writer_cm.as_default():\n",
    "            tf.summary.image(f'{self.network.__name__}-{self.current_time}', cm_image, step=epoch)\n",
    "            \n",
    "    def log_images(self, epoch, logs):\n",
    "        # Create pubs list\n",
    "        self.pubs = list(r.sample(range(0,49), self.samples)) \n",
    "        self.pubs.extend(r.sample(range(50, 99), self.samples))\n",
    "        self.pubs.extend(r.sample(range(100, 149), self.samples))\n",
    "        self.pubs.extend(r.sample(range(150, 199), self.samples))\n",
    "        # Create image paths from test_data\n",
    "        self.data = []\n",
    "        for i in self.pubs:\n",
    "            img = load_img(self.test_data.filepaths[i])\n",
    "            img = img.resize((self.width, self.height)) # width x height\n",
    "            img_arr = np.asarray(img)\n",
    "            self.data.append(img_arr)\n",
    "            \n",
    "        # Data should be in (BATCH_SIZE, H, W, C) \n",
    "        assert np.size(np.shape(self.data)) == 4\n",
    "        # Create a figure to contain the plot.\n",
    "        figure = plt.figure(figsize=(10,10))\n",
    "        num_images = np.shape(self.data)[0]\n",
    "        size = int(np.ceil(np.sqrt(num_images)))\n",
    "\n",
    "        for i in range(len(self.pubs)):\n",
    "            # Start next subplot.\n",
    "            plt.subplot(size, size, i + 1, title=self.class_names[self.test_labels[self.pubs[i]]])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(self.data[i], cmap=plt.cm.binary)\n",
    "\n",
    "        with self.file_writer_image.as_default():        \n",
    "                tf.summary.image(f'{self.network.__name__}-{self.current_time}', \n",
    "                                 Tensorboard.plot_to_image(figure), max_outputs=len(self.pubs), step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e91e6d01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training folder:\n",
      "Found 8311 images belonging to 4 classes.\n",
      "Validation folder:\n",
      "Found 2076 images belonging to 4 classes.\n",
      "\n",
      "Test folder:\n",
      "Found 1000 images belonging to 1 classes.\n",
      "\n",
      "Train data class name and num {'IEEE': 949, 'Macmillan': 2863, 'Springer Nature': 3261, 'Wolters Kluwer Health': 1238}\n",
      "Valid data class name and num {'IEEE': 237, 'Macmillan': 715, 'Springer Nature': 815, 'Wolters Kluwer Health': 309}\n",
      "Num files trained 320 and validated 64 per epoch\n",
      "Images resized to 300x200 trained avg 25.0 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crims\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 12s 778ms/step - loss: 1.1856 - acc: 0.5406 - val_loss: 1.1547 - val_acc: 0.5469\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "v1.summary.FileWriter is not compatible with eager execution. Use `tf.summary.create_file_writer`,or a `with v1.Graph().as_default():` context",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-f233006a9329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmod1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBuildModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'avg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#xception ~ 5e-4, efficient ~ 9e-5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmod1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmod1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-66f508ca260f>\u001b[0m in \u001b[0;36mrun_model\u001b[1;34m(self, summary, proj, save)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;31m# Use the same LOG_DIR where you stored your checkpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0msummary_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;31m# The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \"\"\"\n\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m       raise RuntimeError(\n\u001b[0m\u001b[0;32m    360\u001b[0m           \u001b[1;34m\"v1.summary.FileWriter is not compatible with eager execution. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m           \u001b[1;34m\"Use `tf.summary.create_file_writer`,\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: v1.summary.FileWriter is not compatible with eager execution. Use `tf.summary.create_file_writer`,or a `with v1.Graph().as_default():` context"
     ]
    }
   ],
   "source": [
    "#Args: valid split, width, height, batch_size, steps\n",
    "# batch_size = 32 for Xception and 12 for efficientB5, 16 for B4, 24 for B3\n",
    "dat1 = DataGenerator(0.2, 200, 300, 32, 10)\n",
    "dat1.train_generator()\n",
    "dat1.test_generator()\n",
    "dat1.generator_info()\n",
    "\n",
    "# If the position of objects is important Avg pool if not Max Pooling \n",
    "# Arguments: network, pooling, optimizer, learn_rate, epochs\n",
    "mod1 = BuildModel(dat1, Xception, 'avg', Adam, 1e-4, 1, 4) #xception ~ 5e-4, efficient ~ 9e-5\n",
    "mod1.compile_model()\n",
    "mod1.run_model(False, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6e90a6",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca5394",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Predictor(BuildModel):\n",
    "    def __init__(self, build_model):\n",
    "        self.test_data = build_model.test_data\n",
    "        self.valid_data = build_model.valid_data\n",
    "        self.test_labels = build_model.test_labels\n",
    "        self.width = build_model.width\n",
    "        self.height = build_model.height\n",
    "        self.model = build_model.model\n",
    "        self.class_names = build_model.class_names\n",
    "        self.batch_size = build_model.batch_size\n",
    "             \n",
    "    def img_predict(self):\n",
    "        n = r.randint(0, self.test_data.n)\n",
    "        filenames = self.valid_data.filenames\n",
    "        path = f'{PATH_TRAIN}{filenames[n]}'\n",
    "        pic = mpimg.imread(path)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(pic)\n",
    "        plt.show()\n",
    "\n",
    "        img = tf.keras.preprocessing.image.load_img(path, target_size=(self.width, self.height))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_batch = np.expand_dims(img_array, axis=0)\n",
    "        img_processed = tf.keras.applications.xception.preprocess_input(img_batch)\n",
    "\n",
    "        prediction = self.model(img_processed, training=False)\n",
    "        Top_index = np.argsort(np.max(prediction, axis=0))[-1]\n",
    "        Second_index = np.argsort(np.max(prediction, axis=0))[-2]\n",
    "\n",
    "        sort = np.sort(max(prediction))\n",
    "        print(f'1st predict {self.class_names[Top_index]} with conf {round(sort[len(sort) - 1]*100)}%')\n",
    "        print(f'2nd predict {self.class_names[Second_index]} with conf {round(sort[len(sort) - 2] * 100)}%')           \n",
    "        print(f'Answer is {filenames[n][:]}')\n",
    "        \n",
    "    def batch_evaluate(self, num_batches):\n",
    "        self.steps = num_batches\n",
    "        self.model.evaluate(self.valid_data, batch_size=self.batch_size, steps=self.steps)\n",
    "        \n",
    "    def batch_predict(self, num_predicts):\n",
    "        i = num_predicts\n",
    "        test_pred_raw = self.model.predict(self.test_data)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "        test_labels = self.test_labels\n",
    "        acc = sum(1 for x,y in zip(test_pred[0:i], test_labels[0:i]) if x == y) / len(test_labels[0:i])\n",
    "        print(f'Accuracy of predictions is {acc*100}%')        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a305e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = Predictor(mod1)\n",
    "pred1.img_predict()\n",
    "pred1.batch_predict(100)\n",
    "pred1.batch_evaluate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43961d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
